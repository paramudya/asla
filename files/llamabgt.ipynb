{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import VectorStoreIndex, ServiceContext, SimpleDirectoryReader\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts  import Prompt\n",
    "from llama_index.chat_engine.condense_question import CondenseQuestionChatEngine\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\50287\\\\Documents\\\\lImbad\\\\files'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt='hasil eom januari 2023 Suryamas Dutamakmur dummy dont mind 1'\n",
    "resps[prompt] = {\n",
    "    'resp':new_qeng.query(prompt).response\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result for Suryamas Dutamakmur dummy dont mind 1 at the end of January 2023 is 40.574.315.473.679.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resps[prompt][\"resp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The result for Suryamas Dutamakmur dummy dont mind 1 at the end of January 2023 is 40.574.315.473.679.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resps[prompt][\"resp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#          IMPORT DEPENDENCIES         #\n",
    "########################################\n",
    "\n",
    "# import gradio as gr\n",
    "# import random\n",
    "# import time\n",
    "\n",
    "from llama_index import VectorStoreIndex, ServiceContext, SimpleDirectoryReader, StorageContext, load_index_from_storage\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.prompts  import Prompt\n",
    "from llama_index.chat_engine.condense_question import CondenseQuestionChatEngine\n",
    "\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "########################################\n",
    "#            OPENAI API KEY            #\n",
    "########################################\n",
    "\n",
    "openAIkey = \"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\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = openAIkey\n",
    "\n",
    "########################################\n",
    "#           Instantiate a LLM          #\n",
    "########################################\n",
    "\n",
    "model_name='gpt-4-1106-preview'\n",
    "llm35 = OpenAI(temperature=0, api_token = openAIkey, model='gpt-3.5-turbo')\n",
    "llm4 = OpenAI(temperature=0, api_token = openAIkey, model='gpt-4')\n",
    "llm4t = OpenAI(temperature=0, api_token = openAIkey, model='gpt-4-1106-preview')\n",
    "\n",
    "########################################\n",
    "#              DATA SOURCE             #\n",
    "########################################\n",
    "\n",
    "service_context_query = ServiceContext.from_defaults(llm=llm4t)\n",
    "\n",
    "# Log \n",
    "resps={}\n",
    "\n",
    "# Specify the correct path\n",
    "persist_dir_path = \"../.ipynbs/llama_cek/tren_4_vector\"\n",
    "\n",
    "# Rebuild storage context\n",
    "storage_context = StorageContext.from_defaults(persist_dir=persist_dir_path)\n",
    "\n",
    "# Load index from the storage context\n",
    "new_index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Query Engine\n",
    "new_qeng=new_index.as_query_engine(service_context=service_context_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resps={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.memory import ChatMemoryBuffer\n",
    "\n",
    "memory = ChatMemoryBuffer.from_defaults(token_limit=1500)\n",
    "\n",
    "chat_engine = new_index.as_chat_engine(\n",
    "    chat_mode=\"context\",\n",
    "    memory=memory,\n",
    "    system_prompt=(\n",
    "        \"You are a chatbot, able to have normal interactions, as well as talk\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "response = chat_engine.stream_chat(\"\")\n",
    "for token in response.response_gen:\n",
    "    print(token, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://0.0.0.0:7874\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://localhost:7874/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "with gr.Blocks(theme=gr.themes.Soft()) as asla:\n",
    "    gr.Markdown(\n",
    "    \"\"\"\n",
    "    <div style=\"text-align: center;\">\n",
    "        <div style=\"font-size: 30px\"><b>Automated Service & Language - ASLa</b></div>\n",
    "        <p>Data Science BNI</p>\n",
    "    </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    # BOT LIST QUESTION-RESPONSE \n",
    "    chatbot = gr.Chatbot()\n",
    "    \n",
    "    # INPUT\n",
    "    msg = gr.Textbox(label=\"âŽ for sending\",\n",
    "            placeholder=\"Ask me something\",)\n",
    "    \n",
    "    # CLEAR TEXTBOX & HISTORY\n",
    "    # clear = gr.ClearButton([msg, chatbot])\n",
    "    clear = gr.Button(\"Clear chat\")\n",
    "\n",
    "    # HISTORY\n",
    "    def user(user_message, history):\n",
    "        return \"\", history + [[user_message, None]]\n",
    "    \n",
    "    # RESPONSE\n",
    "    def respond(history): \n",
    "        \n",
    "        # HASIL PENCARIAN ASLA NANTI DISINI\n",
    "        prompt = history[-1][0]\n",
    "        #resps[prompt] = {\n",
    "        #    'resp':new_qeng.query(prompt).response\n",
    "        #}\n",
    "        \n",
    "        suffix = \"\\nApabila ada perhitungan, jabarkan perhitungan yang digunakan. Apabila terdapat periode, tolong jabarkan. Batasi angka dalam bentuk miliar, juta, ribu, maupun ratus dengan titik\"\n",
    "#         angka = \"Batasi semua angka dalam triliun jika lebih dari 1000000000000, batasi dalam bentuk miliar jika angka di antara 1000000000 dan 1000000000000, batasi dalam bentuk juta jika angka di antara 1000000 dan 1000000000, batasi dalam bentuk ribu jika angka di antara 1000 dan 1000000, dan batasi dalam bentuk ratus jika angka di antara 100 dan 1000. Kemudian bulatkan nilai menjadi 2 digit di belakang koma\"\n",
    "#         style = \"Jelaskan seperti kamu adalah konsultan BCG.\"\n",
    "        new_dict={        \n",
    "            'resp':new_qeng.query(prompt+suffix).response            \n",
    "        }\n",
    "        try:\n",
    "            resps[model_name][prompt]=new_dict\n",
    "        except:\n",
    "            resps[model_name]={prompt:new_dict}\n",
    "        print(new_dict)\n",
    "        # Check if the response is already in the dictionary\n",
    "        if 'resp' in new_dict: #prompt in resps\n",
    "            bot_message = new_dict['resp'] #resps[prompt][\"resp\"]\n",
    "        else:\n",
    "            query_result = new_qeng.query(prompt)\n",
    "            if query_result and 'choices' in query_result.response:\n",
    "                response_text = query_result.response['choices'][0]['text']\n",
    "                new_dict['resp'] = response_text #resps[prompt] = {\"resp\": response_text}\n",
    "                bot_message = new_dict['resp'] #bot_message = resps[prompt][\"resp\"]\n",
    "                print(bot_message)\n",
    "            else:\n",
    "                # Handle the case where the response is not available\n",
    "                bot_message = \"Response not available\"\n",
    "\n",
    "        history[-1][1] = \"\"\n",
    "\n",
    "        for word in bot_message:\n",
    "            history[-1][1] += word\n",
    "            time.sleep(0.01)\n",
    "            yield history\n",
    "\n",
    "    msg.submit(user, [msg,chatbot], [msg, chatbot], queue=False).then(\n",
    "        respond, chatbot, chatbot\n",
    "    )\n",
    "    clear.click(lambda: None, None, chatbot, queue=False)\n",
    "\n",
    "asla.queue()\n",
    "asla.launch(server_name=\"0.0.0.0\", server_port=7874, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\50287\\appdata\\roaming\\python\\python39\\site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (6.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from matplotlib) (1.3.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.7.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\50287\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade matplotlib --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gpt-4-1106-preview': {'bagaimana kondisi pengeluaran Astra International pada q2 2023': {'resp': 'Pada Q2 2023, pengeluaran Astra International dapat dihitung dengan menjumlahkan total cash out (aliran uang keluar) dari bulan April hingga Juni 2023. Pengeluaran ini terdiri dari cash out ke bank yang berbeda dan cash out ke bank yang sama (BNI).\\n\\nPengeluaran ke bank yang berbeda (different bank) pada:\\n- April 2023: 10,129,876,953.2\\n- Mei 2023: 4,406,845,147.6\\n- Juni 2023: 14,146,238,835.8\\n\\nPengeluaran ke bank yang sama (BNI) pada:\\n- April 2023: 229,659,862.9\\n- Mei 2023: 594,413,480.6\\n- Juni 2023: 535,385,510.7\\n\\nUntuk mendapatkan total pengeluaran, kita akan menjumlahkan angka-angka tersebut:\\n\\nTotal pengeluaran ke bank yang berbeda = 10,129,876,953.2 + 4,406,845,147.6 + 14,146,238,835.8\\nTotal pengeluaran ke bank yang berbeda = 28,682,960,936.6\\n\\nTotal pengeluaran ke bank yang sama (BNI) = 229,659,862.9 + 594,413,480.6 + 535,385,510.7\\nTotal pengeluaran ke bank yang sama (BNI) = 1,359,458,854.2\\n\\nTotal pengeluaran Q2 2023 = Total pengeluaran ke bank yang berbeda + Total pengeluaran ke bank yang sama (BNI)\\nTotal pengeluaran Q2 2023 = 28,682,960,936.6 + 1,359,458,854.2\\nTotal pengeluaran Q2 2023 = 30,042,419,790.8\\n\\nKita akan membulatkan nilai ini ke dalam bentuk miliar dengan dua digit di belakang koma:\\n\\nTotal pengeluaran Q2 2023 = 30,04 miliar\\n\\nJadi, kondisi pengeluaran Astra International pada Q2 2023 adalah sebesar 30,04 miliar.'}}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'resp': 'Untuk menentukan posisi keuangan Astra International pada Q1 2023, kita akan melihat data end-of-month untuk current account savings account (tabungan dan giro), serta aliran uang masuk dan keluar (cash in dan cash out) dari dan ke bank yang sama atau berbeda.\\n\\n1. Current Account Savings Account (Tabungan dan Giro):\\n   - Januari 2023: 2,52 triliun\\n   - Februari 2023: 6,70 juta\\n   - Maret 2023: 4,46 juta\\n\\n2. Cash In (Aliran Uang Masuk) Same Bank (Dalam Bank, BNI):\\n   - Januari 2023: 0,0\\n   - Februari 2023: 0,0\\n   - Maret 2023: 0,0\\n\\n3. Cash Out (Aliran Uang Keluar) Same Bank (Dalam Bank, BNI):\\n   - Januari 2023: 0,0\\n   - Februari 2023: 0,0\\n   - Maret 2023: 262,07 juta\\n\\n4. Closed-Loop Transactions Percentage Average:\\n   - Januari 2023: 0,0%\\n   - Februari 2023: 0,0%\\n   - Maret 2023: 0,0%\\n\\nDari data di atas, kita dapat melihat bahwa pada Q1 2023, Astra International memiliki jumlah yang signifikan dalam tabungan dan giro pada bulan Januari, tetapi jumlah ini menurun drastis pada bulan Februari dan Maret. Tidak ada catatan aliran uang masuk dari bank yang sama selama periode ini, dan hanya ada catatan aliran uang keluar dari bank yang sama pada bulan Maret. Transaksi closed-loop tidak terjadi selama Q1 2023.\\n\\nJadi, posisi keuangan Astra International pada Q1 2023 ditandai dengan penurunan besar dalam saldo tabungan dan giro dari Januari hingga Maret, dengan sedikit aliran uang keluar pada bulan Maret dan tidak ada aliran uang masuk atau transaksi closed-loop yang tercatat.'}\n"
     ]
    }
   ],
   "source": [
    "resps"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
